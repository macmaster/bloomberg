# hadoop-metrics2.properties
# default configurations for jmx metrics reporting.
# contains some starter configuration sets for various metrics2 sinks.
# 
# syntax: [prefix].[source|sink].[instance].[options]
# See javadoc of package-info.java for org.apache.hadoop.metrics2 for details
# 
# author: Ronald Macmaster (Ronnymacmaster@gmail.com)
# date: 08/02/17


# # 1) FileSink
# # logs to a local system file.
# *.sink.file.period=5
# *.sink.file.class=org.apache.hadoop.metrics2.sink.FileSink
# sink.file.loghome=/var/log
# client.sink.file.filename=${sink.file.loghome}/client.log

# # multiple context example
# # redirect metrics of different contexts to different sinks. (in this case files)
# client.sink.file_jvm.class=org.apache.hadoop.metrics2.sink.FileSink
# client.sink.file_jvm.context=jvm
# client.sink.file_jvm.filename=nodemanager-jvm-metrics.out
# client.sink.file_mapred.class=org.apache.hadoop.metrics2.sink.FileSink
# client.sink.file_mapred.context=mapred
# client.sink.file_mapred.filename=nodemanager-mapred-metrics.out


# # 2) GraphiteSink
# # upload to a graphite server.
# *.sink.graphite.period=5
# *.sink.graphite.class=org.apache.hadoop.metrics2.sink.GraphiteSink
# client.sink.graphite.server_host=localhost
# client.sink.graphite.server_port=7877
# client.sink.graphite.metrics_prefix=client


# # 3) CustomSink (Bloomberg)
# # override the void putMetrics(Metric Record record) method.
# # handle metrics reporting on their own.
# # must override com.bloomberg.bach.metrics.RecordHandler
# *.sink.custom.period=5
# *.sink.custom.class=[path.to.custom.sink.class] 
# # must add another key here of form [prefix].sink.[instance].[option]


# # 4) KafkaSink (Apache)
# # publish metrics to a kafka topic.
# # the sink from Apache Hadoop 3.0.0-beta1-SNAPSHOT has less config flexibility.
# *.sink.kafka.period=2
# *.sink.kafka.class=org.apache.hadoop.metrics2.sink.KafkaSink
# client.sink.kafka.broker_list=localhost:9092
# client.sink.kafka.topic=bach # replace with your topic


# # 5) KafkaSink (Bloomberg)
# # configuration parameters can be found here: 
# # http://kafka.apache.org/documentation/#producerconfigs

# # if the "file" property is defined here, 
# # kafka configuration parameters are read from the file.
# # otherwise, they are sourced from their manual definition here.
# *.sink.kafka.period=2
# client.sink.kafka.class=com.bloomberg.bach.metrics.sink.KafkaSink
# client.sink.kafka.topic=bach # replace with your topic
# # *.sink.kafka.file=producer.properties

# # sample kafka configuration (file parameter undefined)
# client.sink.kafka.bootstrap.servers=localhost:9092
# client.sink.kafka.compression.type=none
# client.sink.kafka.key.serializer=org.apache.kafka.common.serialization.StringSerializer
# client.sink.kafka.value.serializer=org.apache.kafka.common.serialization.StringSerializer
# client.sink.kafka.request.timeout.ms=500

# # # filter example for JVM client metrics.
# # client.sink.kafka.record.filter.class=org.apache.hadoop.metrics2.filter.RegexFilter
# # client.sink.kafka.metric.filter.class=org.apache.hadoop.metrics2.filter.RegexFilter
# # client.sink.kafka.record.filter.include=JvmMetrics
# # client.sink.kafka.metric.filter.include=.*


# # 6) LogSink (Apache / Bloomberg)
# # configuration is enabled by default in the BACH metrics.jar.
# # Sinks metrics messages to an slf4j log.
# # Configure your own logging framework (ex log4j) at deployment time.
# *.sink.log.period=2
# client.sink.log.class=com.bloomberg.bach.metrics.sink.LogSink
# client.sink.log.level=INFO
# client.sink.log.format="%n (%d): %v"
# client.sink.log.prefix="\t- "

# # # filter example for HBase client metrics.
# # client.sink.log.record.filter.class=org.apache.hadoop.metrics2.filter.RegexFilter
# # client.sink.log.metric.filter.class=org.apache.hadoop.metrics2.filter.RegexFilter
# # client.sink.log.record.filter.include=CLIENT|ZOOKEEPER
# # client.sink.log.metric.filter.include=Rpc.*\(Multi\).*
